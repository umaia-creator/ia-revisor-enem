import streamlit as st
import language_tool_python
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
from transformers import MarianMTModel, MarianTokenizer
# ... outras importa√ß√µes ...

# =====================
# Configura√ß√£o
# =====================
st.set_page_config(page_title="Ajuste Fino", page_icon="üìù", layout="centered")

# --- Adicione esta linha para o logo ---
st.image("logo_ajuste_fino.png", width=200) # Ajuste a largura conforme necess√°rio
# ---------------------------------------

st.title("‚úçÔ∏è Ajuste Fino") # Este j√° √© o t√≠tulo que voc√™ colocou

# ... o restante do seu c√≥digo ...

# =====================
# Configura√ß√£o
# =====================
st.set_page_config(page_title="Ajuste Fino", page_icon="üìù", layout="centered")
st.title("‚úçÔ∏è Ajuste Fino")

# LanguageTool (corre√ß√£o PT-BR)
tool = language_tool_python.LanguageTool("pt-BR")

# ======= Carregar modelo LLaMA (ou outro compat√≠vel) =======
# Exemplo: "meta-llama/Llama-2-7b-hf" -> precisa de GPU forte
# Para CPU fraco, use "EleutherAI/gpt-neo-125M"
LLAMA_MODEL = "EleutherAI/gpt-neo-125M"

@st.cache_resource
def carregar_llama(model_name=LLAMA_MODEL):
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(model_name)
    gen = pipeline("text-generation", model=model, tokenizer=tokenizer, device=-1)  # device=-1 = CPU
    return gen

with st.spinner("Carregando modelo LLaMA (pode demorar na primeira vez)..."):
    llama_pipeline = carregar_llama()

# ======= Tradu√ß√£o (MarianMT) =======
TRANSLATION_MODELS = {
    "en": "Helsinki-NLP/opus-mt-pt-en",
    "es": "Helsinki-NLP/opus-mt-pt-es",
    "fr": "Helsinki-NLP/opus-mt-pt-fr",
    "de": "Helsinki-NLP/opus-mt-pt-de",
    "it": "Helsinki-NLP/opus-mt-pt-it",
}

@st.cache_resource
def carregar_mariana(model_name):
    tok = MarianTokenizer.from_pretrained(model_name)
    mod = MarianMTModel.from_pretrained(model_name)
    return tok, mod

def traduzir_mariana(texto, idioma_destino="en"):
    if idioma_destino not in TRANSLATION_MODELS:
        return "Idioma n√£o suportado."
    model_name = TRANSLATION_MODELS[idioma_destino]
    tok, mod = carregar_mariana(model_name)
    batch = tok.prepare_seq2seq_batch([texto], return_tensors="pt")
    translated = mod.generate(**{k: v for k, v in batch.items()})
    tgt = [tok.decode(t, skip_special_tokens=True) for t in translated]
    return tgt[0]

# ======= Fun√ß√µes =======
def corrigir_com_languagetool(texto):
    erros = tool.check(texto)
    texto_corrigido = language_tool_python.utils.correct(texto, erros)
    return texto_corrigido, erros

def revisar_com_llama(texto):
    prompt = (
        "Voc√™ √© um corretor de reda√ß√µes estilo ENEM. "
        "Leia o texto abaixo e retorne:\n"
        "1) Vers√£o revisada com melhor clareza, coes√£o e gram√°tica.\n"
        "2) Sugira 5 conectivos adequados.\n"
        "3) Fa√ßa 2-3 coment√°rios curtos sobre a estrutura.\n\n"
        f"Texto:\n{texto}\n\nResposta:"
    )
    saida = llama_pipeline(
        prompt,
        max_new_tokens=256,   # controla o tamanho da resposta
        do_sample=True,
        top_p=0.9,
        temperature=0.7,      # opcional, d√° mais varia√ß√£o
        num_return_sequences=1
    )
    return saida[0]["generated_text"]


# =====================
# Interface Streamlit
# =====================
texto_usuario = st.text_area("Cole sua reda√ß√£o:", height=300)

col1, col2, col3 = st.columns(3)

with col1:
    if st.button("‚úÖ Corrigir (LanguageTool)"):
        if texto_usuario.strip():
            with st.spinner("Corrigindo texto..."):
                texto_corrigido, erros = corrigir_com_languagetool(texto_usuario)
            st.subheader("Texto Corrigido")
            st.write(texto_corrigido)
            if erros:
                st.subheader("Erros encontrados")
                for e in erros[:20]:
                    st.write(f"- {e.ruleId}: {e.message}")

with col2:
    if st.button("üîé Revisar (LLaMA)"):
        if texto_usuario.strip():
            with st.spinner("Gerando revis√£o com LLaMA..."):
                revisao = revisar_com_llama(texto_usuario)
            st.subheader("Revis√£o (LLaMA)")
            st.write(revisao)

with col3:
    idioma = st.selectbox("Traduzir para:", ["en", "es", "fr", "de", "it"])
    if st.button("üåç Traduzir"):
        if texto_usuario.strip():
            with st.spinner("Traduzindo..."):
                traducao = traduzir_mariana(texto_usuario, idioma)
            st.subheader(f"Tradu√ß√£o ({idioma})")
            st.write(traducao)

st.markdown("---")
st.subheader("üîó Conectivos √∫teis (extra)")
st.write("- Causa: porque, devido a, em raz√£o de")
st.write("- Consequ√™ncia: portanto, assim, por conseguinte")
st.write("- Contraste: contudo, entretanto, por outro lado")
st.write("- Exemplifica√ß√£o: por exemplo, como ilustrado por")
st.write("- Conclus√£o: em suma, finalmente, para concluir")


